import tensorflow as tf
import json
import os

print("=" * 70)
print("ğŸ”§ ARREGLANDO EXPORTACIÃ“N DE MODELO TENSORFLOW.JS")
print("=" * 70)

# Rutas
H5_MODEL = "modelo_cnn_lsp/modelo_cnn_lsp.h5"
TFJS_OUTPUT = "public/tfjs_model"

try:
    # Cargar modelo
    print(f"\nğŸ“‚ Cargando modelo desde: {H5_MODEL}")
    model = tf.keras.models.load_model(H5_MODEL)
    
    print("\nğŸ“Š Arquitectura del modelo:")
    model.summary()
    
    # Verificar que la primera capa tenga input_shape correcta
    input_shape = model.layers[0].input_shape
    print(f"\nâœ“ Input shape: {input_shape}")
    
    # Exportar a TensorFlow.js con configuraciÃ³n correcta
    print(f"\nğŸ“¦ Exportando a TensorFlow.js en: {TFJS_OUTPUT}")
    
    # Usar tfjs converter directamente
    os.makedirs(TFJS_OUTPUT, exist_ok=True)
    
    # Guardar modelo en formato SavedModel primero
    saved_model_dir = "temp_saved_model"
    print(f"\nğŸ’¾ Guardando como SavedModel temporal...")
    tf.saved_model.save(model, saved_model_dir)
    
    # Convertir a TFJS
    import tensorflowjs as tfjs
    
    print(f"\nğŸ”„ Convirtiendo a TensorFlow.js...")
    tfjs.converters.convert_tf_saved_model(
        saved_model_dir,
        TFJS_OUTPUT,
        signature_name='serving_default',
        saved_model_tags='serve'
    )
    
    # Limpiar
    import shutil
    shutil.rmtree(saved_model_dir)
    
    print(f"\nâœ… Â¡Modelo exportado correctamente!")
    print(f"   UbicaciÃ³n: {TFJS_OUTPUT}")
    
    # Verificar archivos
    files = os.listdir(TFJS_OUTPUT)
    print(f"\nğŸ“ Archivos generados:")
    for f in files:
        print(f"   â€¢ {f}")
    
except Exception as e:
    print(f"\nâŒ Error: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 70)
